# Intro to ML Safety

## Unit 2: Robustness

* **Robustness** = the ability of a system to handle adversarial attacks and endure once-in-a-century 'black swan' events.


### Adversarial Robustness
